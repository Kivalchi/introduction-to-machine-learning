{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) How would you define Machine Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning is an application of artificial intelligence (AI) in the form of Algorithms that provides computer systems the ability to automatically learn and improve from experience without being explicitly programmed. Machine learning focuses on the development of computer programs that can access data and use it to learn for themselves without human intervion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) What are the differences between Supervised and Unsupervised Learning? Specify example 3 algorithms for each of these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primary difference between supervised learning and unsupervised learning is the data used in either method of machine learning.\n",
    "\n",
    "1. Supervised learning algorithms are trained using labeled data, while Unsupervised learning algorithms are trained using unlabeled data.\n",
    "\n",
    "2. Supervised learning model takes direct feedback to check if it is predicting correct output or not while Unsupervised learning model does not take any feedback.\n",
    "\n",
    "3. Supervised learning model predicts the output while Unsupervised learning model finds the hidden patterns in data.\n",
    "\n",
    "4. In supervised learning, input data is provided to the model along with the output while In unsupervised learning, only input data is provided to the model.\n",
    "\n",
    "5. The goal of supervised learning is to train the model so that it can predict the output when it is given new data while The goal of unsupervised learning is to find the hidden patterns and useful insights from the unknown dataset.\n",
    "\n",
    "6. Supervised learning can be categorized in Classification and Regression problems while Unsupervised learning does not need any supervision to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) What are the test and validation set, and why would you want to use them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test set is a set of data that is used to test the model after the model has already been trained. The test set is separate from both the training set and validation set.\n",
    "\n",
    "The test set is a set of data that is used to test the model after the model has already been trained. The test set is separate from both the training set and validation set.\n",
    "\n",
    "We use the so that we can calculate the loss after classification also so that the weight of the model can be adjusted to give a more accurate prediction. This helps to accomplish the ultimate goal of machine learning which is to build models that are able to generalize well with better accuracy in prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) What are the main preprocessing steps? Explain them in detail. Why we need to prepare our data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main preprocessing steps are categorized into several steps viz:\n",
    "    \n",
    "    Step 1: Acquire the dataset\n",
    "To build and develop Machine Learning models, you must first acquire the relevant dataset. This dataset will be comprised of data gathered from multiple and disparate sources which are then combined in a proper format to form a dataset. Dataset formats differ according to use cases. For instance, a business dataset will be entirely different from a medical dataset. While a business dataset will contain relevant industry and business data, a medical dataset will include healthcare-related data.\n",
    "\n",
    "    Step 2: Import Libraries\n",
    "Since Python is the most extensively used and also the most preferred library by Data Scientists around the world, 4 basic python libraries are required namely\n",
    "\n",
    "i. Numpy\n",
    "ii. Matplotlib\n",
    "iii. Pandas\n",
    "iv. Seaborn\n",
    "\n",
    "    Step 3: Importing Datasets\n",
    "In this step, we need to import the datasets which we have collected for our machine learning project. This is a function basically done using Pandas libraries.\n",
    "\n",
    "    Step 4: Identifying and Handling Missing Data:\n",
    "In data preprocessing, it is pivotal to identify and correctly handle the missing values, failing to do this might draw inaccurate and faulty conclusions and inferences from the data. Needless to say, this will hamper your Machine Learning project.\n",
    "\n",
    "Basically, there are two ways to handle missing data:\n",
    "\n",
    "1. Deleting a particular row – In this method, you remove a specific row that has a null value for a feature or a particular column where more than 75% of the values are missing. However, this method is not 100% efficient, and it is recommended that you use it only when the dataset has adequate samples. You must ensure that after deleting the data, there remains no addition of bias. \n",
    "\n",
    "2. Calculating the mean/median/mode – This method is useful for features having numeric data like age, salary, year, etc. Here, you can calculate the mean, median, or mode of a particular feature or column or row that contains a missing value and replace the result for the missing value. This method can add variance to the dataset, and any loss of data can be efficiently negated. Hence, it yields better results compared to the first method (omission of rows/columns). Another way of approximation is through the deviation of neighbouring values. However, this works best for linear data.\n",
    "\n",
    "    step 5: Encoding Categorical Data (Feature Encoding):\n",
    "Since machine learning model completely works on mathematics and numbers, if our dataset have a categorical variable, then it may create trouble while building the model. So it is necessary to encode these categorical variables into numbers. This process of feature encoding is basically transforming our dataset such that it can be easily accepted as input for machine learning algorithms whitout changing the original meaning of the data. This is done either by NOMINAL or ORDINAL method.\n",
    "\n",
    "    Step 6. Spliting the Dataset into Training Set, Validation set and Test Set:\n",
    "This process is used to enhance the performance of the Machine learning algorithms in dealing with real-world data\n",
    "\n",
    "Other steps in preprocessing are\n",
    "1. Duplicate Values: Duplicate values are removed from dataset so as not to give that particular data object an advantage pr bias when running machine learning algorithms\n",
    "\n",
    "2. Imbalance Data: This occurs when the number of class(es) instances are significantly higher than the other class(es). This leads to an imbalance and creates a rare and different class(es)\n",
    "    \n",
    "3. Outlier Detection: This is also known as Anomaly detection. It is the identification of rare items, events or observations which raise suspicions by differing significantly from the majority of the data. It is done using standard deviation, Box plus/IQR Calculation or Isolation Forest\n",
    "\n",
    "4. Feature Scalling:  Feature scaling is a method used to normalize/standardize the range of independent variables or features of data. In data processing, it is also known as data normalization.\n",
    "\n",
    "5. Bucketing: This is a preprocessing method used to minimize the effect of small observation errors(noisy data).\n",
    "    \n",
    "    \n",
    "    \n",
    "WHY WE NEED TO PREPARE OUR DATA\n",
    "\n",
    "The reason is simply because almost all dataset are flawed. That’s why data preparation is such an important step in the machine learning process. In a nutshell, data preparation is a set of procedures that helps make your dataset more suitable for machine learning. In broader terms, the dataprep also includes establishing the right data collection mechanism. Machine Learning algorithms requires a partcular formatted into a very specific way which oiginally is different from the raw dataset, for Machine Learning algorithms to produce desired predictions, the dataset has to be prepared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) How you can explore countionus and discrete variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discrete variables. If the possible outcomes of a random variable can be listed out using a finite (or countably infinite) set of single numbers (for example, {0, 1, 2 . . . , 10}; or {-3, -2.75, 0, 1.5}; or {10, 20, 30, 40, 50…} ), then the random variable is discrete. This has two class which are Finite and Infinite discrete variables. This can be explored using Probability Mass Functions\n",
    "\n",
    "Continuous variables. If the possible outcomes of a random variable can only be described using an interval of real numbers (for example, all real numbers from zero to ten, height in cm or depth in meters ), then the random variable is continuous. It typically represents measurements. This can be explored using Probability Density Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
